{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "Error fetching data: 426\n",
      "               publishedAt                                              title  \\\n",
      "0     2024-05-27T23:46:48Z  US stock futures inch higher in slim trade as ...   \n",
      "1     2024-05-27T23:46:06Z  Stocks splits are usually bullish. Here are 8 ...   \n",
      "2     2024-05-27T23:42:04Z  This High-Yield Renewable Energy Stock Offers ...   \n",
      "3     2024-05-27T23:40:10Z  Palantir Stock Could Be Worth 5X Its Current V...   \n",
      "4     2024-05-27T23:40:04Z  CGI announces intent to repurchase 2.89 millio...   \n",
      "...                    ...                                                ...   \n",
      "2995  2024-06-25T21:26:17Z  Stock market today: Nvidia rebounds, and it's ...   \n",
      "2996  2024-06-25T21:25:58Z    22nd Century Group reduces debt by $1.5 million   \n",
      "2997  2024-06-25T21:23:56Z  Saba Capital Management buys Destra Multi-Alte...   \n",
      "2998  2024-06-25T21:23:00Z  Twelve Seas Investment Company II Announces Te...   \n",
      "2999  2024-06-25T21:16:42Z  Crane Advisory LLC Increases Stock Position in...   \n",
      "\n",
      "                                            description  \n",
      "0     US stock futures inch higher in slim trade as ...  \n",
      "1     None Nvidia is the 8th company this year to an...  \n",
      "2     Benzinga and Yahoo Finance LLC may earn commis...  \n",
      "3     Palantir (NYSE:PLTR) is one of the names close...  \n",
      "4     CGI announces intent to repurchase 2.89 millio...  \n",
      "...                                                 ...  \n",
      "2995  A rebound for Nvidia propped up a weakened Wal...  \n",
      "2996    22nd Century Group reduces debt by $1.5 million  \n",
      "2997  Saba Capital Management buys Destra Multi-Alte...  \n",
      "2998  New York, NY, June 25, 2024 (GLOBE NEWSWIRE) -...  \n",
      "2999  Crane Advisory LLC raised its holdings in John...  \n",
      "\n",
      "[3000 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "# Set your API key\n",
    "api_key = 'b07683d4fbed401490f767a345aebfdb'\n",
    "\n",
    "# Define the date range\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=60)  # Extended to 60 days\n",
    "\n",
    "# Fetch news articles in smaller chunks (e.g., daily) to ensure broader coverage\n",
    "articles_list = []\n",
    "\n",
    "for i in range(60):  # Adjusted for 60 days\n",
    "    chunk_start_date = start_date + timedelta(days=i)\n",
    "    chunk_end_date = chunk_start_date + timedelta(days=1)\n",
    "    \n",
    "    url = (f'https://newsapi.org/v2/everything?q=stock market&from={chunk_start_date.strftime(\"%Y-%m-%d\")}'\n",
    "           f'&to={chunk_end_date.strftime(\"%Y-%m-%d\")}&language=en&sortBy=publishedAt&apiKey={api_key}')\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        articles_list.extend(articles)\n",
    "    else:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "\n",
    "# Store the articles in a pandas df\n",
    "df = pd.DataFrame(articles_list)\n",
    "print(df[['publishedAt', 'title', 'description']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Pre-processing & Sentiment Analysis\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get the sentiment score\n",
    "def get_sentiment_score(text):\n",
    "    return sid.polarity_scores(text)['compound'] if text else 0\n",
    "\n",
    "df['sentiment'] = df['description'].apply(get_sentiment_score)\n",
    "\n",
    "# Convert 'publishedAt' to datetime and ensure dates are parsed correctly\n",
    "df['publishedAt'] = pd.to_datetime(df['publishedAt']).dt.date\n",
    "\n",
    "# Group by day and calculate average sentiment\n",
    "df['day'] = df['publishedAt']\n",
    "daily_sentiment = df.groupby('day')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Group by week and calculate average sentiment\n",
    "df['week'] = pd.to_datetime(df['day']).dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weekly_sentiment = df.groupby('week')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Display the daily and weekly sentiment\n",
    "print(daily_sentiment.head(10))\n",
    "print(weekly_sentiment.head(10))\n",
    "\n",
    "# Display the range of dates\n",
    "print(f\"Date range: {df['day'].min()} to {df['day'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the first element of the df here the 1970 date\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching stock market data for daily trends\n",
    "\n",
    "# Define the stock ticker and date range\n",
    "ticker = 'SPY'  # S&P 500 ETF as an example\n",
    "end_date = datetime.now().date()\n",
    "start_date = end_date - timedelta(days=60)  # Extended to 60 days\n",
    "stock_data = yf.download(ticker, start=start_date, end=end_date, interval='1d')\n",
    "\n",
    "# Calculate daily returns\n",
    "stock_data['daily_return'] = stock_data['Adj Close'].pct_change()\n",
    "\n",
    "# Reset the index to join with sentiment data\n",
    "stock_data.reset_index(inplace=True)\n",
    "\n",
    "# Convert Date to date\n",
    "stock_data['Date'] = stock_data['Date'].dt.date\n",
    "\n",
    "# Display the stock data\n",
    "print(\"Stock Data with Daily Returns:\\n\", stock_data[['Date', 'daily_return']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the date ranges in daily_sentiment again after filtering\n",
    "print(\"Filtered Daily Sentiment Dates:\\n\", daily_sentiment['day'].unique())\n",
    "\n",
    "# Verify the date ranges in stock_data\n",
    "print(\"Stock Data Dates:\\n\", stock_data['Date'].unique())\n",
    "\n",
    "# Merging daily sentiment and stock data after filtering invalid dates\n",
    "daily_combined_data = pd.merge(daily_sentiment, stock_data[['Date', 'daily_return']], left_on='day', right_on='Date', how='inner')\n",
    "\n",
    "# Display the daily combined data\n",
    "print(\"Daily Combined Data:\\n\", daily_combined_data.head(10))\n",
    "\n",
    "# Handle missing data\n",
    "daily_combined_data.dropna(subset=['daily_return'], inplace=True)\n",
    "\n",
    "# Display the daily combined data after dropping NaNs\n",
    "print(\"Daily Combined Data After Dropping NaNs:\\n\", daily_combined_data[['day', 'sentiment', 'daily_return']].head(10))\n",
    "\n",
    "# Calculate daily correlation if there are enough data points\n",
    "if len(daily_combined_data) > 1:\n",
    "    daily_correlation = daily_combined_data['sentiment'].corr(daily_combined_data['daily_return'])\n",
    "    print(f'Correlation between daily sentiment and daily stock performance: {daily_correlation}')\n",
    "else:\n",
    "    print(\"Not enough data points to calculate daily correlation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
