{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n",
      "Error fetching data: 429\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['publishedAt', 'title', 'description'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13700/2112746261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;31m# Store the articles in a pandas df\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marticles_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'publishedAt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'title'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3765\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3766\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3767\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3769\u001b[0m         \u001b[1;31m# take() does not accept boolean indexers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   5875\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5876\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5877\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5879\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   5936\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0muse_interval_msg\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5937\u001b[0m                     \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5938\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5940\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of [Index(['publishedAt', 'title', 'description'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from datetime import datetime, timedelta\n",
    "import yfinance as yf\n",
    "# Set your API key\n",
    "api_key = '71015ea355524adaa5463cf1651763b6'\n",
    "\n",
    "# Define the date range\n",
    "end_date = datetime.now()\n",
    "start_date = end_date - timedelta(days=60)  # Extended to 60 days\n",
    "\n",
    "# Fetch news articles in smaller chunks (e.g., daily) to ensure broader coverage\n",
    "articles_list = []\n",
    "\n",
    "for i in range(60):  # Adjusted for 60 days\n",
    "    chunk_start_date = start_date + timedelta(days=i)\n",
    "    chunk_end_date = chunk_start_date + timedelta(days=1)\n",
    "    \n",
    "    url = (f'https://newsapi.org/v2/everything?q=stock market&from={chunk_start_date.strftime(\"%Y-%m-%d\")}'\n",
    "           f'&to={chunk_end_date.strftime(\"%Y-%m-%d\")}&language=en&sortBy=publishedAt&apiKey={api_key}')\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        articles = response.json().get('articles', [])\n",
    "        articles_list.extend(articles)\n",
    "    else:\n",
    "        print(f\"Error fetching data: {response.status_code}\")\n",
    "\n",
    "# Store the articles in a pandas df\n",
    "df = pd.DataFrame(articles_list)\n",
    "print(df[['publishedAt', 'title', 'description']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 2: Pre-processing & Sentiment Analysis\n",
    "nltk.download('vader_lexicon')\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Function to get the sentiment score\n",
    "def get_sentiment_score(text):\n",
    "    return sid.polarity_scores(text)['compound'] if text else 0\n",
    "\n",
    "df['sentiment'] = df['description'].apply(get_sentiment_score)\n",
    "\n",
    "# Convert 'publishedAt' to datetime and ensure dates are parsed correctly\n",
    "df['publishedAt'] = pd.to_datetime(df['publishedAt']).dt.date\n",
    "\n",
    "# Group by day and calculate average sentiment\n",
    "df['day'] = df['publishedAt']\n",
    "daily_sentiment = df.groupby('day')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Group by week and calculate average sentiment\n",
    "df['week'] = pd.to_datetime(df['day']).dt.to_period('W').apply(lambda r: r.start_time)\n",
    "weekly_sentiment = df.groupby('week')['sentiment'].mean().reset_index()\n",
    "\n",
    "# Display the daily and weekly sentiment\n",
    "print(daily_sentiment.head(10))\n",
    "print(weekly_sentiment.head(10))\n",
    "\n",
    "# Display the range of dates\n",
    "print(f\"Date range: {df['day'].min()} to {df['day'].max()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the first element of the df here the 1970 date\n",
    "print(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching stock market data for daily trends\n",
    "\n",
    "# Define the stock ticker and date range\n",
    "ticker = 'SPY'  # S&P 500 ETF as an example\n",
    "end_date = datetime.now().date()\n",
    "start_date = end_date - timedelta(days=60)  # Extended to 60 days\n",
    "stock_data = yf.download(ticker, start=start_date, end=end_date, interval='1d')\n",
    "\n",
    "# Calculate daily returns\n",
    "stock_data['daily_return'] = stock_data['Adj Close'].pct_change()\n",
    "\n",
    "# Reset the index to join with sentiment data\n",
    "stock_data.reset_index(inplace=True)\n",
    "\n",
    "# Convert Date to date\n",
    "stock_data['Date'] = stock_data['Date'].dt.date\n",
    "\n",
    "# Display the stock data\n",
    "print(\"Stock Data with Daily Returns:\\n\", stock_data[['Date', 'daily_return']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the date ranges in daily_sentiment again after filtering\n",
    "print(\"Filtered Daily Sentiment Dates:\\n\", daily_sentiment['day'].unique())\n",
    "\n",
    "# Verify the date ranges in stock_data\n",
    "print(\"Stock Data Dates:\\n\", stock_data['Date'].unique())\n",
    "\n",
    "# Merging daily sentiment and stock data after filtering invalid dates\n",
    "daily_combined_data = pd.merge(daily_sentiment, stock_data[['Date', 'daily_return']], left_on='day', right_on='Date', how='inner')\n",
    "\n",
    "# Display the daily combined data\n",
    "print(\"Daily Combined Data:\\n\", daily_combined_data.head(10))\n",
    "\n",
    "# Handle missing data\n",
    "daily_combined_data.dropna(subset=['daily_return'], inplace=True)\n",
    "\n",
    "# Display the daily combined data after dropping NaNs\n",
    "print(\"Daily Combined Data After Dropping NaNs:\\n\", daily_combined_data[['day', 'sentiment', 'daily_return']].head(10))\n",
    "\n",
    "# Calculate daily correlation if there are enough data points\n",
    "if len(daily_combined_data) > 1:\n",
    "    daily_correlation = daily_combined_data['sentiment'].corr(daily_combined_data['daily_return'])\n",
    "    print(f'Correlation between daily sentiment and daily stock performance: {daily_correlation}')\n",
    "else:\n",
    "    print(\"Not enough data points to calculate daily correlation.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
